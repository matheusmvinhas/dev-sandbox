
# Dev Sandbox

## ğŸ“¦ Sobre o projeto

Este projeto Ã© um ambiente de desenvolvimento **completo e containerizado** para execuÃ§Ã£o e orquestraÃ§Ã£o de pipelines de dados. Ele integra Airflow, Spark, ClickHouse, MinIO e Metabase, proporcionando uma plataforma robusta para testes, anÃ¡lises e validaÃ§Ã£o de ETLs.

## ğŸ—ï¸ Arquitetura do ambiente

O ambiente Ã© totalmente baseado em containers Docker, com cada serviÃ§o isolado e configurado em arquivos `docker-compose` especializados.

**Componentes:**

- **Airflow 3.0:** OrquestraÃ§Ã£o de pipelines com operadores personalizados para execuÃ§Ã£o com Docker.
- **2 x PostgreSQL:** Banco de dados de backend do Airflow e Metabase.
- **Dataplataform (Spark):**  
  - IntegraÃ§Ã£o com Dataflint, Delta Lake, SparkMeasure e PyDeequ para qualidade e performance.  
  - ConexÃ£o com ClickHouse e MinIO.  
  - Suporte a DuckDB para anÃ¡lises locais.
- **ClickHouse:** Banco de dados analÃ­tico columnar.
- **MinIO:** Armazenamento de objetos S3-compatible.
- **Metabase:** VisualizaÃ§Ã£o de dados, com automaÃ§Ã£o de backup de queries e dashboards.
- **Spark History Server:** Monitoramento de jobs Spark.

## ğŸ› ï¸ Tecnologias e ferramentas

- **OrquestraÃ§Ã£o:** Airflow 3.0 + PostgreSQL  
- **Processamento:** Apache Spark + Delta Lake + Dataflint + SparkMeasure + PyDeequ  
- **Armazenamento:** MinIO + DuckDB + ClickHouse  
- **VisualizaÃ§Ã£o:** Metabase  
- **Infraestrutura:** Docker + Docker Compose + Makefile  
- **AutomaÃ§Ã£o:** Scripts shell e utilitÃ¡rios Python  

## ğŸ“ Estrutura do projeto

```
.
â”œâ”€â”€ airflow/               # Airflow config, DAGs, plugins, custom operators
â”œâ”€â”€ clickhouse/           # ConfiguraÃ§Ãµes e scripts de inicializaÃ§Ã£o do ClickHouse
â”œâ”€â”€ dataplataform/        # Spark config, scripts, JARs e testes
â”œâ”€â”€ metabase/             # Backup do banco de dados do Metabase
â”œâ”€â”€ minio/                # InicializaÃ§Ã£o, scripts e dados do MinIO
â”œâ”€â”€ orchestration/        # docker-compose especializados
â”œâ”€â”€ .env / .env.example   # VariÃ¡veis de ambiente
â”œâ”€â”€ makefile              # AutomaÃ§Ã£o de comandos
â””â”€â”€ README.md             # Este arquivo
```


## ğŸ› ï¸ Comandos completos (`Makefile`)

### ğŸ” UtilitÃ¡rios

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make check-env`            | Verifica se o arquivo `.env` existe                              |
| `make airflow-password`     | Exibe a senha gerada do Airflow (modo standalone)                |

### ğŸš€ InicializaÃ§Ã£o

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make up`                   | Sobe **todos os serviÃ§os** com build                              |
| `make up-clickhouse`        | Sobe apenas o ClickHouse                                          |
| `make up-airflow`           | Sobe apenas o Airflow                                             |
| `make up-etl-runner`        | Sobe apenas o ETL Runner (Spark)                                  |
| `make up-metabase`          | Sobe apenas o Metabase                                            |
| `make up-minio`             | Sobe apenas o MinIO                                               |
| `make up-spark-history`     | Sobe apenas o Spark History Server                                |

### â¬‡ï¸ Parada e Reset

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make down`                 | Derruba **todos os containers** sem remover volumes              |
| `make down-clean`           | Derruba **todos os containers** e **remove volumes**             |
| `make reset`                | Derruba e sobe novamente todos os serviÃ§os                       |

### ğŸ§¾ Logs

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make logs-airflow`         | Mostra logs do Airflow                                            |
| `make logs-metabase`        | Mostra logs do Metabase                                           |
| `make logs-clickhouse`      | Mostra logs do ClickHouse                                         |
| `make logs-minio-init`      | Mostra logs do processo de inicializaÃ§Ã£o do MinIO                 |

### ğŸ§ª Testes

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make test`                 | Executa teste de ambiente configurado                             |

### ğŸš€ Setup Completo

| Comando                      | DescriÃ§Ã£o                                                        |
| --------------------------- | ---------------------------------------------------------------- |
| `make init`                 | Executa configuraÃ§Ã£o completa: `check-env`, `up` e `airflow-password` |

### ğŸ’¾ Backup e RestauraÃ§Ã£o do Metabase

| Comando                          | DescriÃ§Ã£o                                                    |
| -------------------------------- | ------------------------------------------------------------ |
| `make backup-metabase-db`        | Realiza backup do banco de dados do Metabase                 |
| `make restore-metabase-db-clean` | Restaura o banco a partir do backup, apagando tudo antes     |

### ğŸ§¹ Limpeza

| Comando                          | DescriÃ§Ã£o                                                    |
| -------------------------------- | ------------------------------------------------------------ |
| `make clean-spark-events`        | Limpa diretÃ³rios de eventos do Spark                         |
| `make minio-clean-all`           | Limpa todos os arquivos dos buckets no MinIO                 |
| `make minio-clean-old`           | Limpa arquivos antigos dos buckets no MinIO                  |
| `make minio-clean-prefix`        | Limpa arquivos de um bucket MinIO baseado em prefixo         |



## âš™ï¸ ConfiguraÃ§Ã£o

1. **VariÃ¡veis de ambiente:**  
   - Copie `.env.example` para `.env`.  
   - Ajuste conforme a necessidade (senhas, portas, etc).

2. **Volumes persistentes:**  
   - Alguns serviÃ§os utilizam volumes locais para manter estado (Ex: `minio/data`, `clickhouse/init-sql`).

3. **DependÃªncias:**  
   - Docker  
   - Docker Compose  
   - Make

## ğŸš€ Como rodar

O ambiente Ã© totalmente gerenciado pelo `Makefile`.  

### **Subir todos os serviÃ§os:**

```bash
make up
```

### **Subir serviÃ§os especÃ­ficos:**

- Airflow: `make up-airflow`  
- ClickHouse: `make up-clickhouse`  
- ETL Runner (Spark): `make up-etl-runner`  
- Metabase: `make up-metabase`  
- MinIO: `make up-minio`  
- Spark History Server: `make up-spark-history`

### **Parar todos os serviÃ§os:**

```bash
make down
```

### **Parar serviÃ§os especÃ­ficos:**

- Airflow: `make down-airflow`  
- ClickHouse: `make down-clickhouse`  
- ETL Runner: `make down-etl-runner`  
- Metabase: `make down-metabase`  
- MinIO: `make down-minio`  
- Spark History Server: `make down-spark-history`

## ğŸ§¹ ManutenÃ§Ã£o e troubleshooting

### **Limpeza de diretÃ³rios:**

- Limpar eventos do Spark:  
  ```bash
  make clean-spark-events
  ```

- Limpar diretÃ³rios de saÃ­da:  
  ```bash
  make clean-output
  ```

- Limpeza completa:  
  ```bash
  make clean-all
  ```

## ğŸ“Š VisualizaÃ§Ã£o de dados

- **Metabase:**  
  - Acesse via: `http://localhost:3000`  
  - Banco de dados configurado com PostgreSQL.  
  - Backup automatizado: `metabase_pg_backup.sql`

- **MinIO:**  
  - Acesse via: `http://localhost:9000`  
  - Credenciais configuradas no `.env`.

- **Spark History Server:**  
  - Monitoramento via interface web apÃ³s subir `make up-spark-history`.

## ğŸ§ª Testes

- Testes e validaÃ§Ãµes de pipelines localizados em `dataplataform/testes`.  
- Scripts de execuÃ§Ã£o de ETL com Spark, validados com:  
  - **SparkMeasure** para performance  
  - **PyDeequ** para qualidade de dados  
- IntegraÃ§Ã£o com **ClickHouse** e **MinIO** para testes fim-a-fim.

## âœ… ConclusÃ£o

Este ambiente provÃª uma infraestrutura robusta para desenvolvimento, testes e validaÃ§Ã£o de pipelines de dados em um ecossistema completo. Use os comandos `make` para gerenciar os serviÃ§os de forma eficiente.
